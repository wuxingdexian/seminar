http://www.oschina.net/translate/spark-tuning
http://www.ibm.com/developerworks/cn/linux/l-sparkdataanalysis/
http://blog.newitfarmer.com/big_data/big-data_computing/spark/13908/repost-spark%E8%B0%83%E4%BC%98%EF%BC%880-8-1%E4%B8%AD%E6%96%87%E7%89%88%EF%BC%89
http://rdc.taobao.org/?p=533

http://www.cnblogs.com/vincent-hv/p/3316502.html


http://spark.apache.org/docs/latest/tuning.html
http://spark.apache.org/docs/latest/scala-programming-guide.html#rdd-persistence



初步确定要优化的方面：
1.使用broadcast变量，类似于Hadoop的本地缓存，使得数据会在每台机子上保存数据备份，而非每个task保存备份。
2.存储级别，目前确定应该使用“MEMORY_AND_DISK ”
3.数据序列化，使用Kryo


问题1：使用kryo序列化，设置MEMORY_AND_DISK的持久化属性，在计算top-k的时候出现了内存溢出的情况。
而使用默认的java序列化，设置设置MEMORY_AND_DISK的持久化属性，在计算top-k的时候没有出现内存溢出的情况。


思路：参考下面的链接，里面提到内存回收问题，这个跟“spark.storage.memoryFraction属性”有关。
http://rdc.taobao.org/?p=2034
http://www.oschina.net/translate/spark-tuning
http://spark.apache.org/docs/0.9.1/tuning.html
通过察看http://www.blogjava.net/kolor/archive/2012/09/07/kryo.html，是否告诉kyro序列化进行反序列化后得到对象占有的空间比将会膨胀好多倍，故而出现了内存溢出等情况？

解决办法：通过观察http://dhu3:4040/executors/，可以监控到内存的实际使用情况，可以据此参考设置“spark.storage.memoryFraction属性”的比值，如设置为0.05甚至更少？


问题2：虽然设置了“spark.storage.memoryFraction属性”的比值到一个更小的值，如0.01，但是最终出现另一个错误：java.lang.NullPointerException
思路：是内存还是不够？http://bohr.me/2013/11/03/kryo-oom.html说“kryo序列化不会存储java 字段信息，他会把属性值按照一定的顺序写到byte数组里面的(没有字段信息)。如果反序列化时，java对象结构变化，就有可能出现今天的悲剧事件。”
解决办法：暂时先使用默认的java内置序列化吧
